<div align="center">

# ğŸš€ Pathfinding Algorithms Comparison

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)]()
[![License](https://img.shields.io/badge/License-MIT-green.svg)]()
[![Status](https://img.shields.io/badge/Status-In%20Progress-yellow.svg)]()

</div>

This repository contains our group project for *COMP 9060 â€“ Advanced Algorithms*, comparing classical and optimized pathfinding algorithms: **A\***, **Dijkstra**, **DFS**, and **JPS (Jump Point Search)**.  
The study focuses on performance, path optimality, and efficiency across different grid-based environments.


## ğŸ‘¥ Team Members
| Name | Role |
|------|------|
| **Yansong** | Algorithm Developer â€“ A*, Dijkstra, DFS Implementation |
| **Sepehr** | QA & Testing Lead â€“ JPS Implementation and Integration |
| **Vibhor** | Evaluation Lead â€“ Metrics Analysis and Visualization |
| **Binger** | Project Manager â€“ Documentation, Reporting, and Presentation |


## ğŸ¯ Project Overview
Pathfinding is a fundamental problem in AI, robotics, and game development.
This project aims to:
- Implement **A***, **Dijkstra**, **DFS**, and **JPS** algorithms in a common grid framework.
- Evaluate their performance on various **grid configurations** (sparse vs dense, small vs large).
- Measure **runtime**, **path cost**, and **node expansions** to analyze algorithmic efficiency.
- Visualize algorithm behavior through comparative charts and heatmaps.
**Jump Point Search (JPS)** improves **A*** by **skipping redundant nodes** in uniform-cost grids, reducing runtime while preserving optimal path cost.


## ğŸ—‚ï¸ Repository Structure
```
pathfinding-optimization/
â”œâ”€â”€ data/                    # Sample grid maps and test cases
â”‚   â””â”€â”€ maps/                # Example .txt or .csv grid files
â”œâ”€â”€ docs/                    # Documentation and reports
â”‚   â”œâ”€â”€ proposal.pdf         # Submitted project proposal
â”‚   â”œâ”€â”€ report_draft.docx    # In-progress final report
â”‚   â””â”€â”€ slides.pptx          # Presentation slides
â”œâ”€â”€ notebooks/                       # Jupyter notebooks for experiments and demos
â”‚   â”œâ”€â”€ 01_astar_demo.ipynb          # Interactive A* pathfinding demo
â”‚   â”œâ”€â”€ 02_dijkstra_runtime.ipynb    # Runtime analysis for Dijkstraâ€™s algorithm
â”‚   â””â”€â”€ 03_visualization_tests.ipynb # Prototyping plots/heatmaps before moving to src/
â”œâ”€â”€ results/                 # Experiment outputs, logs, and performance data
â”‚   â”œâ”€â”€ figures/             # Generated charts and comparison graphs
â”‚   â””â”€â”€ logs/                # Raw runtime and node expansion logs
â”œâ”€â”€ src/                     # Source code for all algorithms
â”‚   â”œâ”€â”€ algorithms/          # Pathfinding algorithm implementations
â”‚   â”‚   â”œâ”€â”€ astar.py         # A* baseline algorithm
â”‚   â”‚   â”œâ”€â”€ dfs.py           # Depth-First Search baseline
â”‚   â”‚   â”œâ”€â”€ dijkstra.py      # Dijkstra baseline algorithm
â”‚   â”‚   â”œâ”€â”€ jps.py           # Jump Point Search (JPS) implementation
â”‚   â”‚   â””â”€â”€ mazegenerator.py # DFS-based random maze generator
â”‚   â”œâ”€â”€ core/                # Shared components
â”‚   â”‚   â”œâ”€â”€ grid.py          # Grid representation and movement rules
â”‚   â”‚   â”œâ”€â”€ heuristics.py    # Heuristic functions (Manhattan, Octile, etc.)
â”‚   â”‚   â””â”€â”€ utils.py         # Utility functions (logging, timers, helpers)
â”‚   â”œâ”€â”€ visualizations/      # Visualization and performance analysis
â”‚   â”‚   â”œâ”€â”€ charts.py        # Static plots for paths and metrics
â”‚   â”‚   â””â”€â”€ runtime_plot.py  # Search-progress / runtime-steps plots
â”‚   â””â”€â”€ main.py              # Entry point to run and compare algorithms
â””â”€â”€ README.md                # Project overview and usage instructions
```


## âš™ï¸ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/bing-er/pathfinding-optimization.git
cd pathfinding-iptimization
```

### 2. Set Up Environment
```
python3 -m venv venv
source venv/bin/activate        # (Mac/Linux)
venv\Scripts\activate           # (Windows)
pip install -r requirements.txt
```

### 3. Run Algorithms
Run individual algorithms:
```
python src/algorithms/astar.py
python src/algorithms/dijkstra.py
python src/algorithms/dfs.py
python src/algorithms/jps.py
```
Or compare all from the main runner:
```
python src/main.py
```
### 4. Visualize Results
Generated logs and performance visualizations will appear in the results/ folder.
You can adjust grid size, obstacle density, or heuristic type in main.py.

### ğŸ“Š Evaluation Metrics

| Metric               | Description                      |
| -------------------- | -------------------------------- |
| **Path Length**      | Total distance of computed route |
| **Computation Time** | Time required to reach goal      |
| **Node Expansions**  | Number of explored nodes         |
| **Scalability**      | Performance on larger grid maps  |

## ğŸ§­ Progress Summary 
### Week 10 â€“ Midterm Status
By Week 11, the team successfully completed integration and began the **performance testing and visualization phase**. All four algorithms (A*, Dijkstra, DFS, JPS) now run under a unified framework, and the testing plan for runtime and node-expansion benchmarking was finalized.

The repository is now fully organized with a clear folder structure, evaluation metrics, and documentation. Everyoneâ€™s roles are defined â€” **Yansong** handled the baseline algorithms, **Sepehr** is leading the **Jump Point Search (JPS)** development, **Vibhor** is focusing on evaluation and visualization, and **Binger** is managing documentation, scheduling, and overall coordination.

Our next milestone is to integrate and test **JPS**, comparing its performance against the baseline algorithms. The team will also begin logging runtime and node-expansion data and preparing visual outputs for comparison. In the following weeks, weâ€™ll move toward compiling the final report, creating visuals, and getting ready for our presentation in Week **14 (Dec 2)**.

### Week 11 - Post-Integration Update
By **Week 11**, our team successfully completed the **integration phase** of the Pathfinding Optimization project. All four pathfinding algorithms â€” **A***, **Dijkstra**, **DFS**, and **JPS** â€” have now been implemented, tested, and unified under a consistent framework.

The repository is fully functional and organized, supporting reproducible experiments, runtime logging, and visualization for performance comparison.

**ğŸ§  Highlights**
* **JPS** algorithm finalized and merged into the main branch.
* **Runtime visualization notebooks** and early performance plots demonstrated in the team meeting.
* **Unified main runner** implemented for all algorithms.
* **Automatic saving of runtime data and figures** into the structured results folders.
* **Enhanced maze generation and visualization** integrated into the main workflow.
* **Performance testing plan finalized** (grid sizes 10Ã—10 â†’ 101Ã—101, sparse vs dense).
* **Visualization notebooks updated** for runtime and node-expansion analysis.
* **Vibhorâ€™s benchmark suite integrated** under notebooks/ for automated comparison.
* **Team reviewed results via meeting (Nov 11, 2025)** â€” confirmed consistent outputs, JPS shows fewer steps but slightly higher runtime.

#### ğŸ‘¥ Team Contributions
**ğŸ§  Yansong**
* Implemented and verified the **A***, **Dijkstra**, and **DFS** baseline algorithms.
* Ensured algorithm correctness, consistent output, and optimal-path validation.
* Assisted in integration testing and aligning algorithm interfaces.

**âš™ï¸ Sepehr**
* Finalized the **Jump Point Search (JPS)** algorithm with jump + pruning logic.
* Verified performance improvements and integrated JPS into the shared framework.
* Supported testing and comparison with baseline algorithms.

**ğŸ“Š Vibhor**
* Finalized and pushed **benchmark testing notebooks** (maze_benchmark_corners.ipynb, .py, .html).
* Designed runtime and path-length comparison plan for all algorithms.
* Coordinated visualization data pipeline for performance analysis.

**ğŸ§© Binger**
* Implemented the **main runner** (`main.py`) with unified execution and `--compare` mode for algorithm benchmarking.
* Developed **logging and visualization tools** (`utils.py`, `charts.py`, `runtime_plot.py`) for runtime and path analysis.
* Enhanced **maze generator** (`mazegenerator.py`) to ensure consistent grids across algorithms.
* Configured automatic saving to `results/figures`/ and `results/logs/` for reproducible experiments.
* Organized and maintained the full repository structure for seamless testing and visualization.
* Reviewed and merged visualization branch (viz_vib) into main.
* Organized follow-up testing tasks and documented meeting summary for Week 11.

## ğŸ“… Next Milestones
* Conduct performance testing on larger grid sizes (21Ã—21, 51Ã—51, 101Ã—101).
* Analyze runtime, path length, and node expansions for all algorithms.
* Finalize visualization outputs and integrate comparison figures.
* Begin drafting the **final report** and **presentation slides** for submission (Week 14 â€“ Dec 2, 2025).


## ğŸ“… Updated Project Timeline

| **Milestone** | **Due Date** | **Status** |
|----------------|--------------|-------------|
| Proposal Submission | Oct 21, 2025 | âœ… Submitted |
| Implementation Phase (A*, Dijkstra, DFS, JPS) | Nov 8, 2025 | âœ… Completed |
| Performance Testing + Visualization | Nov 18, 2025 | âœ… Started (Nov 11 Meeting) |
| Final Report & Presentation | Dec 2, 2025 | â³ Upcoming |


## ğŸ§  Visualization Example
*(Runtime-comparison and search-progress figures will be added after completing batch experiments.)*


## ğŸ“œ License

This project is developed for **educational purposes** under the **BCIT COMP 9060 â€“ Applied Algorithm Analysis** course.  
Licensed under the [MIT License](LICENSE).


### ğŸ”— **Useful Links**

- ğŸ“˜ [Overleaf Proposal](https://www.overleaf.com/9465635879vhhjjwjkmhzk#37ad93)  
- ğŸ“„ [Overleaf Final Report](https://www.overleaf.com/6623247675ghmpxqtkrbhc#20506f)  
- ğŸ—‚ï¸ [GitHub Project Board](https://github.com/yourusername/COMP9060-Pathfinding-Optimization/projects)  
- ğŸ“Š [Results Dashboard (optional)](https://colab.research.google.com/drive/your-dashboard-link)
